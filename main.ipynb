{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edac6315-5690-4ac6-b67e-eb70dc160051",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pdb\n",
    "import time\n",
    "import math\n",
    "import shutil\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tools_data as td\n",
    "import dataLaoder as dl\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import itertools\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from tqdm.notebook import tqdm_notebook\n",
    "\n",
    "from torch.utils.data import  DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9c07d7e6-8668-4ec4-b217-2aa448555901",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(object):\n",
    "    def __init__(self,model,optim) :\n",
    "        self.model = model\n",
    "        self.optim = optim\n",
    "        self.epoch ,self.iter =0,0\n",
    "\n",
    "    def getEpoch(self):\n",
    "        return self.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b0b9ecca-7be7-44ec-a2f6-4893b90a9da3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'if __name__ == \"__main__\":\\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\\n    model = VGG_net(in_channels=3, num_classes=1000).to(device)\\n    print(model)\\n    ## N = 3 (Mini batch size)\\n    x = torch.randn(1, 3, 32, 32).to(device)\\n    print(model(x).shape)'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "\n",
    "VGG_types = {\n",
    "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
    "    \"VGG16\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "    \"VGG19\": [\n",
    "        64,\n",
    "        64,\n",
    "        \"M\",\n",
    "        128,\n",
    "        128,\n",
    "        \"M\",\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        256,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        512,\n",
    "        \"M\",\n",
    "    ],\n",
    "}\n",
    "\n",
    "\n",
    "class VGG_net(nn.Module):\n",
    "    def __init__(self, in_channels=3, num_classes=1000):\n",
    "        super(VGG_net, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG11\"])\n",
    "\n",
    "        self.fcs = nn.Sequential(\n",
    "            nn.Linear(512 , 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=0.2),\n",
    "            nn.Linear(512, 10),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv_layers(x)\n",
    "        x = x.reshape(x.shape[0], -1)\n",
    "        x = self.fcs(x)\n",
    "        return x\n",
    "\n",
    "    def create_conv_layers(self, architecture):\n",
    "        layers = []\n",
    "        in_channels = self.in_channels\n",
    "\n",
    "        for x in architecture:\n",
    "            if type(x) == int:\n",
    "                out_channels = x\n",
    "\n",
    "                layers += [\n",
    "                    nn.Conv2d(\n",
    "                        in_channels=in_channels,\n",
    "                        out_channels=out_channels,\n",
    "                        kernel_size=(3, 3),\n",
    "                        stride=(1, 1),\n",
    "                        padding=(1, 1),\n",
    "                    ),\n",
    "                    nn.BatchNorm2d(x),\n",
    "                    nn.ReLU(),\n",
    "                ]\n",
    "                in_channels = x\n",
    "            elif x == \"M\":\n",
    "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
    "\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "\n",
    "\"\"\"if __name__ == \"__main__\":\n",
    "    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model = VGG_net(in_channels=3, num_classes=1000).to(device)\n",
    "    print(model)\n",
    "    ## N = 3 (Mini batch size)\n",
    "    x = torch.randn(1, 3, 32, 32).to(device)\n",
    "    print(model(x).shape)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d87713d-613c-40a0-81a5-4f876dea4687",
   "metadata": {},
   "outputs": [],
   "source": [
    "svhn_train_x,svhn_train_y = td.load_svhn_train('./data/svhn/train_32x32.mat')\n",
    "svhn_test_x,svhn_test_y = td.load_svhn_train('./data/svhn/test_32x32.mat')\n",
    "\n",
    "svhn_train_x = svhn_train_x.transpose([0, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6ed02b3-1a1e-4887-a9d6-328f39fbb84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cifar10_train_x,cifar_train_y = td.load_cifar10_set('./data/cifar-10/cifar-10-batches-py/data_batch_')\n",
    "cifar10_test_x,cifar_test_y = td.load_cifar10_one('./data/cifar-10/cifar-10-batches-py/test_batch')\n",
    "\n",
    "cifar10_train_x = cifar10_train_x.transpose([0, 3, 2, 1])\n",
    "cifar10_test_x = cifar10_test_x.transpose([0, 3, 2, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f74cade2-4fb2-48ba-86e9-17937abd5eb1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in_train = dl.MyDataSet(cifar10_train_x,cifar_train_y)\\nin_test = dl.MyDataSet(cifar10_test_x,np.array(cifar_test_y))\\n\\n\\nout_train = dl.MyDataSet(svhn_train_x,svhn_train_y)\\nout_test = dl.MyDataSet(svhn_test_x,svhn_test_y)'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"in_train = dl.MyDataSet(cifar10_train_x,cifar_train_y)\n",
    "in_test = dl.MyDataSet(cifar10_test_x,np.array(cifar_test_y))\n",
    "\n",
    "\n",
    "out_train = dl.MyDataSet(svhn_train_x,svhn_train_y)\n",
    "out_test = dl.MyDataSet(svhn_test_x,svhn_test_y)\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "898bda39-35a3-4aa4-8718-2925a7b07c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "def epoch_batches(data_x,data_y,nb_batches,nb_cls):\n",
    "    \n",
    "    indx_cls,indx_no_cls = [],[]\n",
    "    \n",
    "    left_data = []\n",
    "    right_data = []\n",
    "    y_b = []\n",
    "    y = []\n",
    "    one_batch_x = []\n",
    "    one_batch_y = []\n",
    "    x = []\n",
    "    \n",
    "    \n",
    "    for m in range(len(np.unique(data_y))):\n",
    "        indx_cls.append(np.where(data_y == m)[0])\n",
    "        indx_no_cls.append(np.where(data_y != m)[0])\n",
    "    \n",
    "    for btc in range(nb_batches):\n",
    "        for cl in range(0,nb_cls):\n",
    "            \n",
    "            random.shuffle(indx_cls[cl])\n",
    "            random.shuffle(indx_no_cls[cl])\n",
    "            \n",
    "            \n",
    "            left_data.append(data_x[indx_cls[cl][0:10]][:])\n",
    "            right_data.append(data_x[indx_cls[cl][10:20]][:])\n",
    "            y_b.append([1 for i in range(0,10)])\n",
    "            \n",
    "            cla = random.shuffle(indx_cls[cl])\n",
    "            \n",
    "            left_data.append(data_x[indx_cls[cl][0:30]][:])\n",
    "            right_data.append(data_x[indx_no_cls[cl][30:60]][:])\n",
    "            y_b.append([0 for i in range(0,30)])\n",
    "        \n",
    "        left_data = list(itertools.chain(*left_data))\n",
    "        right_data = list(itertools.chain(*right_data))\n",
    "        one_batch_x = left_data+right_data\n",
    "        one_batch_y = list(itertools.chain(*y_b)) + list(itertools.chain(*y_b))\n",
    "        \n",
    "        x.append(one_batch_x)\n",
    "        y.append(one_batch_y)\n",
    "        \n",
    "        one_batch_x = []\n",
    "        one_batch_y = []\n",
    "        left_data = []\n",
    "        right_data =[]\n",
    "        y_b = []\n",
    "        \n",
    "    x = list(itertools.chain(*x))\n",
    "    y = list(itertools.chain(*y))\n",
    "    \n",
    "    \n",
    "    data = dl.MyDataSet(np.array(x),np.array(y))\n",
    "    data = DataLoader(dataset=data,batch_size=800 ,shuffle = False , num_workers=2)\n",
    "            \n",
    "    return data\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06bb76ae-650f-4e1f-ba1e-bec0b4aa873a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = epoch_batches(cifar10_train_x,cifar_train_y,75,10) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "019f4bd7-2b81-4aee-970f-2d56b7b67748",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntmp = 0         \\n#d_train = epoch_batches(cifar10_train_x,cifar_train_y,75,10) \\n    \\nfor x,y in data :\\n            \\n            \\n    #optim.zero_grad()\\n            \\n    #xhat = net(x)\\n            \\n\\n    anchors_x = x[0:x.shape[0]//2]\\n    y = y[0:y.shape[0]//2]\\n            \\n            \\n    pos_neg_x = x[x.shape[0]//2:x.shape[0]]\\n    # pos_neg_y = y[xhat.shape[0]//2:xhat.shape[0]]\\n        \\n    if tmp == 0 : \\n        #plt.figure(figsize=(40,900))\\n        print(y.shape)\\n        #t = 1\\n        \\n        #for i in range(300):\\n            \\n            # print(y[i])\\n            #plt.subplot(300,2,t)\\n\\n            #plt.imshow(np.array(anchors_x[i]).transpose([ 2, 1, 0]))\\n            #t += 1 \\n            #plt.subplot(300,2,t)\\n            #t += 1 \\n            #plt.imshow(np.array(pos_neg_x[i]).transpose([ 2, 1, 0]))\\n        #plt.show()\\n    tmp += 1\\n        '"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "tmp = 0         \n",
    "#d_train = epoch_batches(cifar10_train_x,cifar_train_y,75,10) \n",
    "    \n",
    "for x,y in data :\n",
    "            \n",
    "            \n",
    "    #optim.zero_grad()\n",
    "            \n",
    "    #xhat = net(x)\n",
    "            \n",
    "\n",
    "    anchors_x = x[0:x.shape[0]//2]\n",
    "    y = y[0:y.shape[0]//2]\n",
    "            \n",
    "            \n",
    "    pos_neg_x = x[x.shape[0]//2:x.shape[0]]\n",
    "    # pos_neg_y = y[xhat.shape[0]//2:xhat.shape[0]]\n",
    "        \n",
    "    if tmp == 0 : \n",
    "        #plt.figure(figsize=(40,900))\n",
    "        print(y.shape)\n",
    "        #t = 1\n",
    "        \n",
    "        #for i in range(300):\n",
    "            \n",
    "            # print(y[i])\n",
    "            #plt.subplot(300,2,t)\n",
    "\n",
    "            #plt.imshow(np.array(anchors_x[i]).transpose([ 2, 1, 0]))\n",
    "            #t += 1 \n",
    "            #plt.subplot(300,2,t)\n",
    "            #t += 1 \n",
    "            #plt.imshow(np.array(pos_neg_x[i]).transpose([ 2, 1, 0]))\n",
    "        #plt.show()\n",
    "    tmp += 1\n",
    "        \"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bfc209fe-c275-4504-a089-c71d9859df6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in_train_laoder = DataLoader(dataset=in_train,batch_size=800 ,shuffle = True,num_workers=2)\n",
    "#in_test_laoder = dataTestLoader = DataLoader(dataset=in_test,batch_size=200,shuffle = True,num_workers=2)\n",
    "\n",
    "#out_train_laoder = dataTestLoader = DataLoader(dataset=out_train,batch_size=150,shuffle = True,num_workers=2)\n",
    "#out_test_laoder = dataTestLoader = DataLoader(dataset=out_test,batch_size=1,shuffle = True,num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19eecc74-b36f-4329-88e9-ef842515a9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "259144f2-1970-46c6-a828-d18e3e39f413",
   "metadata": {},
   "outputs": [],
   "source": [
    "def euclidean_dist(x, y):\n",
    "    m, n = x.size(0), y.size(0)\n",
    "    xx = torch.pow(x, 2).sum(1, keepdim=True).expand(m, n)\n",
    "    yy = torch.pow(y, 2).sum(1, keepdim=True).expand(n, m).t()\n",
    "    dist = xx + yy\n",
    "    dist.addmm_(1, -2, x, y.t())\n",
    "    dist = dist.clamp(min=1e-12).sqrt()  # for numerical stability\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "513a4316-bdda-450d-93dd-48da0d1c0efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MetricLearning(nn.Module):\n",
    "    def __init__(self, weight=None, size_average=True):\n",
    "        super(MetricLearning, self).__init__()\n",
    " \n",
    "    def forward(self, y_compare, pos_neg_x,anchors_x, smooth=1):        \n",
    "        \n",
    "    \n",
    "        Dw = euclidean_dist(anchors_x , pos_neg_x)\n",
    "    \n",
    "        p_p = 0.5*y_compare*torch.pow(Dw,2)\n",
    "        \n",
    "        \n",
    "        m = torch.maximum((10.0-Dw),torch.tensor(0.0))\n",
    "        \n",
    "        p_n = 0.5*(1-y_compare)*torch.pow(m,2)\n",
    "        \n",
    "        \n",
    "        # print(torch.mean(p_p),torch.mean(p_n))\n",
    "        return torch.mean(p_p+ p_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0537d9e8-580c-46bc-8e79-d22e5d7ba994",
   "metadata": {},
   "outputs": [],
   "source": [
    "    net = VGG_net(in_channels=3, num_classes=1000).to(device)\n",
    "    optim = torch.optim.Adam(net.parameters(),lr=0.0001,    weight_decay = 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a7c7f724-5826-466f-9204-434bf132c714",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "savepath = Path('models.pch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2bd201e6-35ef-47de-9541-3b7e6626ceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_net(x_train,y_train,data_out):\n",
    "\n",
    "    #writer = SummaryWriter(\"runs\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    if savepath.is_file():\n",
    "        print('Restarting from previous state')\n",
    "        with savepath.open('rb') as fp :\n",
    "            state = torch.load(fp)\n",
    "            myloss = MetricLearning()\n",
    "            \n",
    "    else : \n",
    "        net = VGG_net(in_channels=3, num_classes=1000).to(device)\n",
    "        optim = torch.optim.Adam(net.parameters(),lr=0.0001,    weight_decay = 1e-4)\n",
    "        myloss = MetricLearning()\n",
    "        \n",
    "        state = State(net, optim)\n",
    "        \n",
    "    l = []\n",
    "    \n",
    "    state.optim = torch.optim.Adam(state.model.parameters(),lr=0.00001 ,    weight_decay = 1e-4)\n",
    "    #state = State(net, optim)\n",
    "        \n",
    "    \n",
    "    for epoch in tqdm_notebook(range(state.epoch,3000), desc = 'Epochs'):\n",
    "        \n",
    "        d_train = epoch_batches(cifar10_train_x,cifar_train_y,75,10) \n",
    "        \n",
    "        tmp = 0\n",
    "        \n",
    "        if epoch == 150 :\n",
    "            state.optim = torch.optim.Adam(net.parameters(),lr=0.00001 ,    weight_decay = 1e-4) \n",
    "            \n",
    "        if epoch == 2250 :\n",
    "            state.optim =  torch.optim.Adam(net.parameters(),lr=0.00001 ,    weight_decay = 1e-4) \n",
    "        \n",
    "        for x,y in d_train :\n",
    "            \n",
    "            x = x.to(device)\n",
    "            y = y.to(device)\n",
    "            \n",
    "            state.optim.zero_grad()\n",
    "            \n",
    "            \n",
    "            xhat = state.model(x)\n",
    "            \n",
    "\n",
    "            anchors_x = xhat[0:xhat.shape[0]//2]\n",
    "            y_compare = y[0:y.shape[0]//2]\n",
    "            \n",
    "            \n",
    "            pos_neg_x = xhat[xhat.shape[0]//2:xhat.shape[0]]\n",
    "            #pos_neg_y = y[xhat.shape[0]//2:xhat.shape[0]]\n",
    "            \n",
    "            #y_compare = torch.eq( anchors_y , pos_neg_y).int()\n",
    "            #y_compare = y_compare.to(device)\n",
    "            \n",
    "            #Dw = (anchors_x - pos_neg_x).pow(2).sum(1).sqrt()\n",
    "\n",
    "            \n",
    "            #loss = torch.mean((0.5*torch.pow((y_compare*Dw),2) + 0.5*torch.pow(torch.multiply((1-y_compare),torch.max((10.0-Dw))),2)**2))\n",
    "            \n",
    "            \n",
    "            \n",
    "            loss = myloss(y_compare, pos_neg_x,anchors_x, smooth=1)\n",
    "            \n",
    "            tmp += loss\n",
    "            loss.backward()\n",
    "            state.optim.step()\n",
    "            state.iter += 1\n",
    "        \n",
    "        with savepath.open('wb') as fp :\n",
    "            state.epoch = epoch+1\n",
    "            torch.save(state,fp)\n",
    "            \n",
    "        print(tmp/75)\n",
    "            \n",
    "        l.append(tmp/75)\n",
    "        \n",
    "\n",
    "        \n",
    "    return net , l\n",
    "            \n",
    "            \n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "be6487f4-1f34-4eea-82a1-fcebf48b3ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Restarting from previous state\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f8f2538be0d74c3c92a72649c4bb81dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epochs:   0%|          | 0/2654 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hider/.local/lib/python3.6/site-packages/ipykernel_launcher.py:6: UserWarning: This overload of addmm_ is deprecated:\n",
      "\taddmm_(Number beta, Number alpha, Tensor mat1, Tensor mat2)\n",
      "Consider using one of the following signatures instead:\n",
      "\taddmm_(Tensor mat1, Tensor mat2, *, Number beta, Number alpha) (Triggered internally at  ../torch/csrc/utils/python_arg_parser.cpp:1050.)\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(10.2074, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2176, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2122, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2118, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2178, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2105, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2107, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2190, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2014, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2126, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2109, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2084, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2067, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.1961, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2031, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2129, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2027, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2091, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2061, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2152, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2093, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2032, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2071, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2177, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2085, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2065, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2106, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2041, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2146, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2096, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2059, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.1973, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2123, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2140, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2173, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2108, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2079, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2137, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2134, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2219, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2130, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2037, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2111, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2090, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2043, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2054, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2104, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.1992, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2136, device='cuda:0', grad_fn=<DivBackward0>)\n",
      "tensor(10.2196, device='cuda:0', grad_fn=<DivBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-6fb4f4a3d583>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-679b3fd31724>\u001b[0m in \u001b[0;36mtrain_net\u001b[0;34m(x_train, y_train, data_out)\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Epochs'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0md_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_batches\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcifar10_train_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcifar_train_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m75\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-d32a70447711>\u001b[0m in \u001b[0;36mepoch_batches\u001b[0;34m(data_x, data_y, nb_batches, nb_cls)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindx_cls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindx_no_cls\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcl\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/random.py\u001b[0m in \u001b[0;36mshuffle\u001b[0;34m(self, x, random)\u001b[0m\n\u001b[1;32m    275\u001b[0m                 \u001b[0;31m# pick an element in x[:i+1] with which to exchange x[i]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    276\u001b[0m                 \u001b[0mj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandbelow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 277\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    278\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    279\u001b[0m             \u001b[0m_int\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "res = train_net([],[],[])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec16ff29-fbb6-42fd-a180-7ffec091bfea",
   "metadata": {},
   "outputs": [],
   "source": [
    "net,loss = res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b9224e-4db8-4a87-93fc-668fd2052df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "    myloss = MetricLearning()    \n",
    "    for x,y in in_train_laoder : \n",
    "            x = x.to(device)\n",
    "            xhat = net(x)\n",
    "            anchors_x = xhat[0:xhat.shape[0]//2]\n",
    "            anchors_y = y[0:y.shape[0]//2]\n",
    "            \n",
    "            \n",
    "            pos_neg_x = xhat[xhat.shape[0]//2:xhat.shape[0]]\n",
    "            pos_neg_y = y[xhat.shape[0]//2:xhat.shape[0]]\n",
    "            \n",
    "            y_compare = torch.eq( anchors_y , pos_neg_y).int()\n",
    "            y_compare = y_compare.to(device)\n",
    "            lt = myloss(y_compare, pos_neg_x,anchors_x, smooth=1)\n",
    "            \n",
    "    print(lt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
